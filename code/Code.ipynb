{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Code.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"stunning-oasis"},"source":["## Set Environment"],"id":"stunning-oasis"},{"cell_type":"code","metadata":{"scrolled":true,"tags":[],"id":"foster-confidence"},"source":["# Dependency Env Setting\n","!apt-get install libgl1-mesa-glx -y\n","!pip install ipywidgets\n","!pip install efficientnet_pytorch\n","!pip install adamp"],"id":"foster-confidence","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"typical-cowboy"},"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import PIL\n","import os\n","import time\n","import glob\n","import pickle\n","import random\n","from pathlib import Path\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from efficientnet_pytorch import EfficientNet\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import f1_score\n","from adamp import AdamP\n","\n","# Set random seed\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True\n","print(f'seed : {seed}')\n","\n","# Set device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f'device : {device}')\n","print(torch.cuda.get_device_properties(device))\n","\n","# Set ROOT_PATH\n","ROOT_PATH = os.getcwd()\n","print(f'ROOT_PATH : {ROOT_PATH}')\n","\n","# Set Training Name\n","'각 실험의 name을 설정하고 Directory형태로 관리하기 위한 Code입니다.'\n","name = 'Dropout-B4'\n","if not os.path.isdir(f'custom_data/{name}') :\n","    os.chdir(os.path.join(ROOT_PATH, 'custom_data'))\n","    os.mkdir(f'{name}')\n","    os.chdir(ROOT_PATH)"],"id":"typical-cowboy","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dangerous-spread"},"source":["## Set Train Data"],"id":"dangerous-spread"},{"cell_type":"code","metadata":{"id":"genetic-documentary"},"source":["# Set Image Directory Path\n","path = Path('input/data/train/images')\n","img_dirs = [str(x) for x in list(path.glob('*')) if '._' not in str(x)]\n","img_dirs = np.array(img_dirs)\n","\n","# Set Semi-label\n","'Class별 층화추출을 위한 Code입니다.'\n","semi_labels = []\n","for img_dir in img_dirs :\n","    if 'female' in img_dir :\n","        g = 1\n","    else :\n","        g = 0\n","    \n","    age = int(img_dir.split('_')[3][:2])\n","    if age < 30 :\n","        a = 0\n","    elif age < 58 :\n","        a = 1\n","    else : \n","        a = 2\n","    semi_labels.append(3*g + a)\n","semi_labels = np.array(semi_labels)\n","\n","# Set Train set and Valid set\n","'사람(ID)기준으로 층화추출하는 Code입니다.'\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","folds = []\n","for t,v in skf.split(img_dirs, semi_labels) :\n","    folds.append({'train':t, 'valid':v})"],"id":"genetic-documentary","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"international-nylon"},"source":["def labeling(img_path) :\n","    'Mask의 여부까지 포함하여, 최종 Labeling을 수행하는 함수입니다.'\n","    if 'normal' in img_path :\n","        m = 2\n","    elif 'incorrect_mask' in img_path :\n","        m = 1\n","    else :\n","        m = 0\n","\n","    if 'female' in img_path :\n","        g = 1\n","    else :\n","        g = 0\n","\n","    age = int(img_path.split('_')[3][:2])\n","    if age < 30 :\n","        a = 0\n","    elif age < 58 :\n","        a = 1\n","    else : \n","        a = 2\n","    \n","    return 6*m + 3*g + a"],"id":"international-nylon","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"editorial-denial"},"source":["# Define Dataset\n","class FaceDataset(Dataset) :\n","    '''\n","    training의 여부에 따라 Label의 반환 여부가 결정됩니다.\n","    return type은 dict입니다.\n","    '''\n","    def __init__(self, img_paths, trsf, aug=None, training=False) :\n","        self.img_paths = img_paths\n","        self.trsf = trsf\n","        self.aug = aug\n","        self.training = training\n","    \n","    def __len__(self) :\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx) :\n","        img = cv2.imread(self.img_paths[idx])\n","        \n","        if self.aug is not None :\n","            img = self.aug(image=img)['image']\n","            img = self.trsf(img)\n","        else : \n","            img = self.trsf(img)\n","        \n","        if self.training :\n","            label = labeling(self.img_paths[idx])\n","            return {'image' : img, 'label' : label}\n","        else :\n","            return {'image' : img}"],"id":"editorial-denial","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"confidential-allergy"},"source":["## Define Model "],"id":"confidential-allergy"},{"cell_type":"code","metadata":{"id":"reflected-reputation"},"source":["# Deffine Model\n","class MyEfficientNet(nn.Module) :\n","    '''\n","    EfiicientNet-b4의 출력층만 변경합니다.\n","    한번에 18개의 Class를 예측하는 형태의 Model입니다.\n","    '''\n","    def __init__(self) :\n","        super(MyEfficientNet, self).__init__()\n","        self.EFF = EfficientNet.from_pretrained('efficientnet-b4', in_channels=3, num_classes=18)\n","    \n","    def forward(self, x) :\n","        x = self.EFF(x)\n","        x = F.softmax(x, dim=1)\n","        return x"],"id":"reflected-reputation","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"future-solomon"},"source":["## Define Transform and Augs"],"id":"future-solomon"},{"cell_type":"code","metadata":{"id":"circular-difference"},"source":["class ToTensor(object) :\n","    'Input Image를 255로 나눈 후, FloatTensor로 반환합니다.'\n","    def __call__(self, img) :\n","        img = np.array(img)/255\n","        img = img.transpose((2,0,1))\n","        img = torch.FloatTensor(img)\n","        return img"],"id":"circular-difference","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"musical-iceland"},"source":["# Set Transform\n","'Train에 경우에만, 일부 Augmentation을 추가합니다.'\n","'다른 실험의 경우 CenterCrop의 Size를 변경합니다.'\n","train_transform = T.Compose([\n","    T.ToPILImage(),\n","    T.CenterCrop([300,256]),\n","    T.RandomHorizontalFlip(0.5),\n","    T.RandomRotation(10),\n","    ToTensor(),\n","    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","])\n","\n","valid_transform = T.Compose([\n","    T.ToPILImage(),\n","    T.CenterCrop([300,256]),\n","    ToTensor(),\n","    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","])"],"id":"musical-iceland","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nuclear-certification"},"source":["## Set Train Options"],"id":"nuclear-certification"},{"cell_type":"code","metadata":{"id":"perceived-muscle"},"source":["# Set Hyper-params\n","'Batch Size는 Center Crop의 크기에 따라 변경될 수 있습니다.'\n","batch_size = 32\n","lr = 1e-4\n","epochs = 20"],"id":"perceived-muscle","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"relevant-stuff"},"source":["# Set Weight\n","'전체 Class의 분포에 따라 가중치를 구합니다.'\n","img_paths = [str(x) for x in list(path.glob('*/*')) if '._' not in str(x)]\n","img_labels = list(map(labeling, img_paths))\n","\n","label_weights = pd.Series(img_labels).value_counts().sort_index()\n","label_weights = torch.FloatTensor([1-(x/(sum(label_weights))) for x in label_weights])\n","label_weights = label_weights.to(device)"],"id":"relevant-stuff","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lovely-madagascar"},"source":["## Training"],"id":"lovely-madagascar"},{"cell_type":"code","metadata":{"scrolled":true,"tags":[],"id":"adjustable-newport"},"source":["# Training and Validating\n","'일부 Fold만을 사용해 Testing할 경우를 대비한 Code 설계입니다.'\n","folds_index = [0,1,2,3,4] # 0 ~ 4\n","'Loss Function 실험 시 쉽게 변경할 수 있도록 한 Code 설계입니다.'\n","loss_fn = torch.nn.CrossEntropyLoss(weight=label_weights)\n","\n","for fold in folds_index :\n","    print(f'Now Training Fold is {fold}')\n","    valid_loss_min = 3\n","    early_stop_cnt = 0\n","    \n","    '각 Fold에 해당하는 Dataset과 Dataloader가 정의되는 Code입니다.'\n","    train_img_paths, valid_img_paths = [], []\n","    for train_dir in img_dirs[folds[fold]['train']] :\n","        train_img_paths.extend(glob.glob(train_dir+'/*'))\n","    for valid_dir in img_dirs[folds[fold]['valid']] :\n","        valid_img_paths.extend(glob.glob(valid_dir+'/*'))\n","    \n","    train_dataset = FaceDataset(train_img_paths, train_transform, training=True)\n","    valid_dataset = FaceDataset(valid_img_paths, valid_transform, training=True)\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n","    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size//4, shuffle=True, num_workers=3)\n","    \n","    # Re-training Code\n","    '학습이 도중에 종료될 경우에도, 재학습이 가능하도록 설계한 Code입니다.'\n","    retrain_model = glob.glob(f'custom_data/{name}/{fold}fold*{name}.pth')\n","    if retrain_model :\n","        _, _, ep, loss, _ = ''.join(retrain_model).split('_')\n","        ep = int(ep.replace('epoch', ''))\n","        valid_loss_min = float(loss)\n","        model = MyEfficientNet()\n","        model.EFF._dropout = torch.nn.Dropout(p=0.7, inplace=False)\n","        model.load_state_dict(torch.load(retrain_model[0]))\n","        model.to(device)\n","    else : \n","        ep = 0\n","        model = MyEfficientNet()\n","        model.EFF._dropout = torch.nn.Dropout(p=0.7, inplace=False)\n","        model = model.to(device)\n","    \n","    'Optimizer 실험 시 변경이 쉽도록 설계한 Code입니다.'\n","    optim = AdamP(model.parameters(), lr=lr)\n","    \n","    for epoch in range(epochs) :\n","        # If Re-training\n","        if epoch < ep :\n","            continue\n","            \n","        # Training\n","        '학습의 진행 상황을 tqdm으로 표시합니다.'\n","        with tqdm(train_loader,\n","                 total=train_loader.__len__(),\n","                 unit='batch') as train_bar :\n","            train_f1 = []\n","            train_loss = []\n","            for sample in train_bar :\n","                train_bar.set_description(f'Epoch {epoch+1} / {epochs}')\n","                imgs = sample['image'].float().to(device)\n","                labels = sample['label'].long().to(device)\n","                \n","                model.train()\n","                optim.zero_grad()\n","                pred = model(imgs)\n","                loss = loss_fn(pred, labels)\n","                loss.backward()\n","                optim.step()\n","                \n","                'f1 score와 loss가 표시됩니다.'\n","                train_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n","                train_loss.append(loss.item())\n","                train_bar.set_postfix(f1=np.mean(train_f1), loss=np.mean(train_loss), Train=epoch+1)\n","        \n","        # Validating\n","        '검증의 진행 상황을 tqdm으로 표시합니다.'\n","        with tqdm(valid_loader,\n","                 total=valid_loader.__len__(),\n","                 unit='batch') as valid_bar :\n","            valid_f1 = []\n","            valid_loss = []\n","            for sample in valid_bar :\n","                valid_bar.set_description(f'Epoch {epoch+1} / {epochs}')\n","                imgs = sample['image'].float().to(device)\n","                labels = sample['label'].long().to(device)\n","                \n","                model.eval()\n","                optim.zero_grad()\n","                with torch.no_grad() : \n","                    pred = model(imgs)\n","                    loss = loss_fn(pred, labels)\n","\n","                'f1 score와 loss가 표시됩니다.'\n","                valid_f1.append(f1_score(labels.cpu().detach().float(), torch.argmax(pred.cpu().detach(), 1), average='macro'))\n","                valid_loss.append(loss.item())\n","                valid_bar.set_postfix(f1=np.mean(valid_f1), loss=np.mean(valid_loss), Valid=epoch+1)\n","        \n","        '검증 단계에서 Loss가 더 낮아지는 경우, 해당 Model을 저장하는 Code입니다.'\n","        if np.mean(valid_loss) < valid_loss_min :\n","            valid_loss_min = np.mean(valid_loss)\n","            early_stop_cnt = 0\n","            for f in glob.glob(f'custom_data/{name}/{fold}fold_*{name}.pth') :\n","                open(f, 'w').close()\n","                os.remove(f)\n","            torch.save(model.state_dict(), f'custom_data/{name}/{fold}fold_{epoch+1}epoch_{np.mean(valid_loss):2.4f}_{name}.pth')\n","        else :\n","            '학습이 진전되지 않는 경우 조기종료하는 Code입니다.'\n","            early_stop_cnt += 1\n","            if early_stop_cnt >= 5 : break"],"id":"adjustable-newport","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"human-baghdad"},"source":["## Inference"],"id":"human-baghdad"},{"cell_type":"code","metadata":{"id":"outstanding-leader"},"source":["# Ensemble Inference\n","'해당 실험에서 학습한 Model을 Ensemble하는 Code입니다.'\n","os.chdir(ROOT_PATH)\n","submission = pd.read_csv('input/data/eval/info.csv')\n","test_img_paths = [os.path.join('input/data/eval/images', img_file) for img_file in submission.ImageID]\n","\n","test_dataset = FaceDataset(test_img_paths, valid_transform, training=False)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","prediction_lst = []\n","for best_model in glob.glob(f'custom_data/{name}/*{name}.pth') :\n","    model = MyEfficientNet()\n","    model.load_state_dict(torch.load(best_model))\n","    model.to(device)\n","    model.eval()\n","    prediction_array=[]\n","    \n","    with tqdm(test_loader,\n","             total=test_loader.__len__(),\n","             unit='batch') as test_bar :\n","        for sample in test_bar :\n","            imgs = sample['image'].float().to(device)\n","            probs = model(imgs)\n","            probs = probs.cpu().detach().numpy()\n","            prediction_array.extend(probs)\n","    \n","    prediction_lst.append(np.array(prediction_array)[...,np.newaxis])\n","\n","submission['ans'] = np.argmax(np.mean(np.concatenate(prediction_lst, axis=2), axis=2), axis=1)\n","submission.to_csv(f'custom_data/{name}/{name}.csv', index=False)"],"id":"outstanding-leader","execution_count":null,"outputs":[]}]}